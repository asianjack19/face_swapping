{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <div style=\"text-align:center\"><u>Realtime Face Swapping</u></div>\n",
    "<table style=\"width:100%; border: solid 1px black\">\n",
    "  <tr style=\"border: solid 1px black\">\n",
    "    <td style=\"text-align:left; border: solid 1px black\"><b>Michael Adriel Darmawan</b></td>\n",
    "    <td style=\"text-align:left; border: solid 1px black\"><b>Juan Farell Haryanto</b></td>\n",
    "    <td style=\"text-align:left; border: solid 1px black\"><b>Jordan Jonathan Gouw</b></td>\n",
    "  </tr>\n",
    "  <tr style=\"border: solid 1px black\">\n",
    "    <td style=\"text-align:left; border: solid 1px black\"><b>2301854170</b></td>\n",
    "    <td style=\"text-align:left; border: solid 1px black\"><b>2301855072</b></td>\n",
    "    <td style=\"text-align:left; border: solid 1px black\"><b>2301852291</b></td>\n",
    "  </tr>\n",
    "   <tr style=\"border: solid 1px black\">\n",
    "    <td style=\"text-align:left; border: solid 1px black\"><b>LA02</b></td>\n",
    "    <td style=\"text-align:left; border: solid 1px black\"><b>LA02</b></td>\n",
    "    <td style=\"text-align:left; border: solid 1px black\"><b>LA02</b></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a function to extract an index from numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractIndexFromNumpyArray(nparray):\n",
    "    index = None\n",
    "    for num in nparray[0]:\n",
    "        index = num\n",
    "        break\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prepare source image and convert it to grayscale\n",
    "4. Create a mask of the same size as the source image\n",
    "5. Create face detector instance and facial landmark points predictor instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceImg = cv2.imread(\"faces/shaq.jpg\")\n",
    "sourceImgGray = cv2.cvtColor(sourceImg, cv2.COLOR_BGR2GRAY)\n",
    "sourceImgMask = np.zeros_like(sourceImgGray)\n",
    "\n",
    "vidCapture = cv2.VideoCapture(0)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create an array to save the indexes of delaunay triangles points of the source image\n",
    "7. Detect faces in the source image\n",
    "8. For each detected face, extract the facial landmarks and append the points to the array, then convert the array to numpy array\n",
    "9. Create a convex hull of the points of the face in the source image\n",
    "10. Create a rectangle that bounds the convex hull\n",
    "11. Using Subdiv2D, create a Delaunay triangulation of the convex hull inside the rectangle\n",
    "12. Save triangle indexes of the Delaunay triangulation to the array, convert the array to numpy array\n",
    "13. For each point of the triangle in the Delaunay triangulation that exist in the facial landmark points, extract the points of the triangle and append the points to the array (Finding the corrdinates of the facial landmarks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "delaunayTrianglesIndexes = []\n",
    "faces = detector(sourceImgGray)\n",
    "for face in faces:\n",
    "    landmarks = predictor(sourceImgGray, face)\n",
    "    landmarkPointsSource = []\n",
    "    for n in range(0, 68):\n",
    "        x = landmarks.part(n).x\n",
    "        y = landmarks.part(n).y\n",
    "        landmarkPointsSource.append((x, y))\n",
    "\n",
    "    points = np.array(landmarkPointsSource, np.int32)\n",
    "    convexhull = cv2.convexHull(points)\n",
    "    cv2.fillConvexPoly(sourceImgMask, convexhull, 255)\n",
    "\n",
    "    rect = cv2.boundingRect(convexhull)\n",
    "    subdiv = cv2.Subdiv2D(rect)\n",
    "    subdiv.insert(landmarkPointsSource)\n",
    "    triangles = subdiv.getTriangleList()\n",
    "    triangles = np.array(triangles, dtype=np.int32)\n",
    "\n",
    "    for t in triangles:\n",
    "        point1 = (t[0], t[1])\n",
    "        point2 = (t[2], t[3])\n",
    "        point3 = (t[4], t[5])\n",
    "\n",
    "        point1Index = np.where((points == point1).all(axis=1))\n",
    "        point1Index = extractIndexFromNumpyArray(point1Index)\n",
    "\n",
    "        point2Index = np.where((points == point2).all(axis=1))\n",
    "        point2Index = extractIndexFromNumpyArray(point2Index)\n",
    "\n",
    "        point3Index = np.where((points == point3).all(axis=1))\n",
    "        point3Index = extractIndexFromNumpyArray(point3Index)\n",
    "\n",
    "        if point1Index is not None and point2Index is not None and point3Index is not None:\n",
    "            triangle = [point1Index, point2Index, point3Index]\n",
    "            delaunayTrianglesIndexes.append(triangle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Convert video capture to grayscale\n",
    "15. Create a mask of the same size as the video capture\n",
    "16. Detect faces in the video capture\n",
    "17. For each detected face, extract the facial landmarks and append the points to the array, then convert the array to numpy array\n",
    "18. Create a convex hull of the points of the face in the video capture\n",
    "19. Loop through all triangles and draw the triangles based on each of the corrdinates for both the source image and the video capture  \n",
    "20. Extract the points of the triangle and mask the triangles in the source image and the video capture\n",
    "21. Using affine transformation, we warp the triangles in source image to match the triangles in the video capture\n",
    "22. For each iteration of the triangles, we add the warped triangles of the source image to the video capture\n",
    "23. Add median blur to the face\n",
    "24. Put the face to the video capture by creating a mask first and then using the mask to put the face to the video capture\n",
    "25. Use seamless clone to match the color of the face in the source image to the face in the video capture\n",
    "26. Sharpening the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    _, targetFace = vidCapture.read()\n",
    "    targetFaceGray = cv2.cvtColor(targetFace, cv2.COLOR_BGR2GRAY)\n",
    "    targetFaceMask = np.zeros_like(targetFace)\n",
    "\n",
    "    faces2 = detector(targetFaceGray)\n",
    "    for face in faces2:\n",
    "        landmarkPointsTarget = []\n",
    "        landmarks = predictor(targetFaceGray, face)\n",
    "        for n in range(0, 68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            landmarkPointsTarget.append((x, y))\n",
    "\n",
    "        pointsTarget = np.array(landmarkPointsTarget, np.int32)\n",
    "        convexhull2 = cv2.convexHull(pointsTarget)\n",
    "\n",
    "    # Triangulation of both faces\n",
    "    for triangleIndex in delaunayTrianglesIndexes:\n",
    "        # Triangulation of the first face\n",
    "        sourcePoint1 = landmarkPointsSource[triangleIndex[0]]\n",
    "        sourcePoint2 = landmarkPointsSource[triangleIndex[1]]\n",
    "        sourcePoint3 = landmarkPointsSource[triangleIndex[2]]\n",
    "        triangleSource = np.array([sourcePoint1, sourcePoint2, sourcePoint3], np.int32)\n",
    "\n",
    "        rectangleSource = cv2.boundingRect(triangleSource)\n",
    "        (x, y, w, h) = rectangleSource\n",
    "        croppedTriangleSource = sourceImg[y: y + h, x: x + w]\n",
    "        croppedTriangleSourceMask = np.zeros((h, w), np.uint8)\n",
    "\n",
    "        pointsSource = np.array([[sourcePoint1[0] - x, sourcePoint1[1] - y],\n",
    "                           [sourcePoint2[0] - x, sourcePoint2[1] - y],\n",
    "                           [sourcePoint3[0] - x, sourcePoint3[1] - y]], np.int32)\n",
    "\n",
    "        cv2.fillConvexPoly(croppedTriangleSourceMask, pointsSource, 255)\n",
    "\n",
    "        # Triangulation of second face\n",
    "        targetPoint1 = landmarkPointsTarget[triangleIndex[0]]\n",
    "        targetPoint2 = landmarkPointsTarget[triangleIndex[1]]\n",
    "        targetPoint3 = landmarkPointsTarget[triangleIndex[2]]\n",
    "        triangleTarget = np.array([targetPoint1, targetPoint2, targetPoint3], np.int32)\n",
    "\n",
    "        rectangleTarget = cv2.boundingRect(triangleTarget)\n",
    "        (x, y, w, h) = rectangleTarget\n",
    "        croppedTriangleTargetMask = np.zeros((h, w), np.uint8)\n",
    "\n",
    "        pointsTarget = np.array([[targetPoint1[0] - x, targetPoint1[1] - y],\n",
    "                            [targetPoint2[0] - x, targetPoint2[1] - y],\n",
    "                            [targetPoint3[0] - x, targetPoint3[1] - y]], np.int32)\n",
    "\n",
    "        cv2.fillConvexPoly(croppedTriangleTargetMask, pointsTarget, 255)\n",
    "\n",
    "        # Warp triangles\n",
    "        pointsSource = np.float32(pointsSource)\n",
    "        pointsTarget = np.float32(pointsTarget)\n",
    "        M = cv2.getAffineTransform(pointsSource, pointsTarget)\n",
    "        warpedTriangle = cv2.warpAffine(croppedTriangleSource, M, (w, h))\n",
    "        warpedTriangle = cv2.bitwise_and(\n",
    "            warpedTriangle, warpedTriangle, mask=croppedTriangleTargetMask)\n",
    "\n",
    "        # Reconstructing destination face\n",
    "        targetFaceRectangle =targetFaceMask[y: y + h, x: x + w]\n",
    "        targetFaceRectangleGray = cv2.cvtColor(\n",
    "            targetFaceRectangle, cv2.COLOR_BGR2GRAY)\n",
    "        _, maskedTriangle = cv2.threshold(\n",
    "            targetFaceRectangleGray, 20, 255, cv2.THRESH_BINARY_INV)\n",
    "        warpedTriangle = cv2.bitwise_and(\n",
    "            warpedTriangle, warpedTriangle, mask=maskedTriangle)\n",
    "\n",
    "        targetFaceRectangle = cv2.add(\n",
    "            targetFaceRectangle, warpedTriangle)\n",
    "        targetFaceRectangle = cv2.medianBlur(targetFaceRectangle, 3)\n",
    "        targetFaceMask[y: y + h, x: x + w] = targetFaceRectangle\n",
    "\n",
    "    # Face swapped (putting 1st face into 2nd face)\n",
    "    resultFaceMask = np.zeros_like(targetFaceGray)\n",
    "    resultHeadMask = cv2.fillConvexPoly(resultFaceMask, convexhull2, 255)\n",
    "    resultFaceMask = cv2.bitwise_not(resultHeadMask)\n",
    "\n",
    "    resultHeadOnly = cv2.bitwise_and(targetFace, targetFace, mask=resultFaceMask)\n",
    "    result = cv2.add(resultHeadOnly, targetFaceMask)\n",
    "\n",
    "    (x, y, w, h) = cv2.boundingRect(convexhull2)\n",
    "    faceCenter = (int((x + x + w) / 2), int((y + y + h) / 2))\n",
    "    seamlessClone = cv2.seamlessClone(\n",
    "        result, targetFace, resultHeadMask, faceCenter, cv2.MIXED_CLONE)\n",
    "\n",
    "    # create kernel to sharpen image with small effect\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                       [-1, 5, -1],\n",
    "                       [0, -1, 0]])\n",
    "    seamlessClone = cv2.filter2D(seamlessClone, -1, kernel)\n",
    "\n",
    "    cv2.namedWindow('Face Swapped', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Face Swapped', 1600, 950)\n",
    "    cv2.imshow('Face Swapped', seamlessClone)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "vidCapture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c712491b74c9d6f5609eeec8d1c925e3977b20a2d9c0418e0448122d650feb4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
